<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:media="http://search.yahoo.com/mrss/"><channel><title>LLMs on MiaoMiaoYang's BLOG</title><link>https://miaomiaoyoung.github.io/en/categories/llms/</link><description>Recent content in LLMs on MiaoMiaoYang's BLOG</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>miaomiaoyangyxy@gmail.com (MiaoMiaoYang)</managingEditor><webMaster>miaomiaoyangyxy@gmail.com (MiaoMiaoYang)</webMaster><copyright>©2023, All Rights Reserved</copyright><lastBuildDate>Sat, 19 Nov 2022 15:01:38 +0800</lastBuildDate><atom:link href="https://miaomiaoyoung.github.io/en/categories/llms/index.xml" rel="self" type="application/rss+xml"/><item><title>Large Language Model</title><link>https://miaomiaoyoung.github.io/en/posts/%E5%AD%A6%E4%B9%A0/papers/llms/</link><pubDate>Sat, 19 Nov 2022 15:01:38 +0800</pubDate><author>miaomiaoyangyxy@gmail.com (MiaoMiaoYang)</author><atom:modified>Sat, 19 Nov 2022 15:01:38 +0800</atom:modified><guid>https://miaomiaoyoung.github.io/en/posts/%E5%AD%A6%E4%B9%A0/papers/llms/</guid><description>CODE load in 4/8 bit 当模型太大的时候，很难加载到普通显卡中，可以使用4/8 bit模型来进行训练 https://huggingface.co/docs/transformers/main_classes/quantization 1 2 3 4 5 6 7 # pip install transformers accelerate bitsandbytes from transformers import AutoModelForCausalLM, AutoTokenizer model_id = &amp;#34;bigscience/bloom-1b7&amp;#34; tokenizer = AutoTokenizer.from_pretrained(model_id) model = AutoModelForCausalLM.from_pretrained(model_id,</description><dc:creator>MiaoMiaoYang</dc:creator><category>学习</category><category>work</category><category>paper</category><category>LLMs</category></item></channel></rss>